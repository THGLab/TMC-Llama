{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing SMILES and Errors\n",
    "\n",
    "This notebook runs a **conversion pipeline** from raw SMILES text files to analysis-ready CSV files:\n",
    "\n",
    "1. **TXT → R_*.csv** — Collect unique SMILES from each `.txt` file and record ID and occurrence count.\n",
    "2. **R_*.csv → E_*.csv** — Check parsability with RDKit, compute canonical SMILES where possible, and attach parse error/warning messages.\n",
    "3. **E_*.csv → errors.csv** — Classify unparsable SMILES by error type (syntax vs chemical) and summarize counts per file.\n",
    "\n",
    "Inputs: `.txt` files in `./txt/` (one SMILES per line).  \n",
    "Outputs: `./par/R_*.csv`, `./par/E_*.csv`, and `./data/errors.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "import pandas as pd\n",
    "from rdkit.Chem.rdmolfiles import MolToSmiles\n",
    "\n",
    "from libTMC.parse_mol_and_errors import get_parsability, append_error_messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline 1: Unique SMILES (TXT → R_*.csv)\n",
    "\n",
    "For each `.txt` file in `txt/`, we read SMILES (one per line), assign a unique ID and count occurrences, then write `par/R_{basename}.csv` with columns: **ID**, **LLM_SMI**, **Occur**. Files already present in `par/` are skipped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files processed: 1\n"
     ]
    }
   ],
   "source": [
    "repodir = '.'\n",
    "txtdir = 'txt'\n",
    "outdir = 'par'\n",
    "\n",
    "os.makedirs(os.path.join(repodir, outdir), exist_ok=True)\n",
    "\n",
    "existing = [\n",
    "    n.replace('.csv', '').split('_')[-1]\n",
    "    for n in os.listdir(os.path.join(repodir, outdir))\n",
    "    if 'R_' in n and n.endswith('.csv')\n",
    "]\n",
    "processed = 0\n",
    "for file in os.listdir(os.path.join(repodir, txtdir)):\n",
    "    if not file.endswith('.txt'):\n",
    "        continue\n",
    "    pre_check = file.replace('.txt', '')\n",
    "    if pre_check in existing:\n",
    "        continue\n",
    "    processed += 1\n",
    "    with open(os.path.join(repodir, txtdir, file), 'r') as f:\n",
    "        info = f.readlines()\n",
    "\n",
    "    identical = {}\n",
    "    begin = 0\n",
    "    for line in info:\n",
    "        smi = line.split('\\n')[0].strip()\n",
    "        if not smi:\n",
    "            continue\n",
    "        if smi not in identical:\n",
    "            begin += 1\n",
    "            identical[smi] = {'ID': begin, 'Occur': 1}\n",
    "        else:\n",
    "            identical[smi]['Occur'] += 1\n",
    "\n",
    "    output_data = defaultdict(list)\n",
    "    for key, values in identical.items():\n",
    "        output_data['ID'].append(values['ID'])\n",
    "        output_data['LLM_SMI'].append(key)\n",
    "        output_data['Occur'].append(values['Occur'])\n",
    "    outputdf = pd.DataFrame(output_data)\n",
    "    param = file.replace('.txt', '')\n",
    "    outputdf.to_csv(os.path.join(repodir, outdir, f'R_{param}.csv'))\n",
    "print('Files processed:', processed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline 2: Parsability and canonical SMILES (R_*.csv → E_*.csv)\n",
    "\n",
    "For each `R_*.csv` in `par/`, we run RDKit parsability checks. Parsable SMILES are canonicalized and merged by canonical SMILES (occurrences and redundant IDs/SMILES aggregated). Unparsable rows keep the original SMILES and get parse error/warning/problem columns. Output: `par/E_{basename}.csv` with **ID**, **Canon_SMI**, **LLM_SMI**, **Occur**, **Parsable**, **RSC_IDs**, **RSC_SMIs**, **Parse_errors**, **Parse_warns**, **Parse_probs**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files processed: 1\n"
     ]
    }
   ],
   "source": [
    "pardir = 'par'\n",
    "existing_e = [\n",
    "    n.replace('.csv', '').replace('E', '')\n",
    "    for n in os.listdir(pardir)\n",
    "    if 'E_' in n and n.endswith('.csv')\n",
    "]\n",
    "processed = 0\n",
    "for file in os.listdir(pardir):\n",
    "    if not file.endswith('.csv') or 'R' not in file:\n",
    "        continue\n",
    "    filename = file.replace('.csv', '').replace('R', '')\n",
    "    if filename in existing_e:\n",
    "        continue\n",
    "    processed += 1\n",
    "    df = pd.read_csv(os.path.join(pardir, file)).drop(columns=['Unnamed: 0'], errors='ignore')\n",
    "\n",
    "    identical = {}\n",
    "    for idx, smi, occur in zip(df['ID'], df['LLM_SMI'], df['Occur']):\n",
    "        mol, parsable, messages = get_parsability(smi)\n",
    "        if parsable:\n",
    "            c_smi = MolToSmiles(mol, canonical=True)\n",
    "            if c_smi not in identical:\n",
    "                identical[c_smi] = {\n",
    "                    'ID': idx, 'Canon_SMI': c_smi, 'LLM_SMI': smi, 'Occur': occur,\n",
    "                    'Parsable': parsable, 'RSC_IDs': '', 'RSC_SMIs': '', 'Messages': messages\n",
    "                }\n",
    "            else:\n",
    "                identical[c_smi]['Occur'] += occur\n",
    "                identical[c_smi]['RSC_IDs'] += (',' if identical[c_smi]['RSC_IDs'] else '') + str(idx)\n",
    "                identical[c_smi]['RSC_SMIs'] += (',' if identical[c_smi]['RSC_SMIs'] else '') + smi\n",
    "        else:\n",
    "            identical[smi] = {\n",
    "                'ID': idx, 'Canon_SMI': smi, 'LLM_SMI': smi, 'Occur': occur,\n",
    "                'Parsable': parsable, 'RSC_IDs': '', 'RSC_SMIs': '', 'Messages': messages\n",
    "            }\n",
    "\n",
    "    outputdict = defaultdict(list)\n",
    "    for k, v in identical.items():\n",
    "        for key, value in v.items():\n",
    "            if key != 'Messages':\n",
    "                outputdict[key].append(value)\n",
    "            else:\n",
    "                append_error_messages(outputdict, value, subtitle='Parse')\n",
    "    outputdf = pd.DataFrame(outputdict)\n",
    "    outputdf.to_csv(os.path.join(pardir, f'E{filename}.csv'))\n",
    "print('Files processed:', processed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline 3: Error classification (E_*.csv → errors.csv)\n",
    "\n",
    "We classify **unparsable** SMILES by the content of their parse messages:\n",
    "- **Chemical**: Improper valences, Kekulization issues, Aromatic labels for non-ring atoms, or multiple chemical issues.\n",
    "- **Syntax**: Unclosed rings, Parentheses, Duplicate bonds on ring closure, Other syntax errors.\n",
    "\n",
    "Each E_*.csv is summarized into one row of counts; results are written to `./data/errors.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "psftdir = 'par'\n",
    "files = [f for f in os.listdir(psftdir) if f.endswith('.csv') and 'E_' in f]\n",
    "\n",
    "chemdict = {\n",
    "    'Improper valences': 'Explicit valence',\n",
    "    'Kekulization issues': 'kekulize',\n",
    "    'Aromatic labels for non-ring atoms': 'non-ring'\n",
    "}\n",
    "syndict = {\n",
    "    'Unclosed rings': 'unclosed ring',\n",
    "    'Parentheses': 'parentheses',\n",
    "    'Duplicate bonds on ring closure': 'ring closure',\n",
    "    'Other syntax errors': 'syntax error while parsing'\n",
    "}\n",
    "errdict = {}\n",
    "for key, value in chemdict.items():\n",
    "    errdict[value] = {'Label': key, 'Occur': 0, 'Class': 'Chemical'}\n",
    "for key, value in syndict.items():\n",
    "    errdict[value] = {'Label': key, 'Occur': 0, 'Class': 'Syntax'}\n",
    "errdict['multiple'] = {'Label': 'Multiple chemical issues', 'Occur': 0, 'Class': 'Chemical'}\n",
    "\n",
    "chemphs = list(chemdict.values())\n",
    "allphs = list(errdict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Info</th>\n",
       "      <th>Improper valences|Chemical</th>\n",
       "      <th>Kekulization issues|Chemical</th>\n",
       "      <th>Aromatic labels for non-ring atoms|Chemical</th>\n",
       "      <th>Unclosed rings|Syntax</th>\n",
       "      <th>Parentheses|Syntax</th>\n",
       "      <th>Duplicate bonds on ring closure|Syntax</th>\n",
       "      <th>Other syntax errors|Syntax</th>\n",
       "      <th>Multiple chemical issues|Chemical</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E_example</td>\n",
       "      <td>148</td>\n",
       "      <td>166</td>\n",
       "      <td>8</td>\n",
       "      <td>549</td>\n",
       "      <td>35</td>\n",
       "      <td>19</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Info  Improper valences|Chemical  Kekulization issues|Chemical  \\\n",
       "0  E_example                         148                           166   \n",
       "\n",
       "   Aromatic labels for non-ring atoms|Chemical  Unclosed rings|Syntax  \\\n",
       "0                                            8                    549   \n",
       "\n",
       "   Parentheses|Syntax  Duplicate bonds on ring closure|Syntax  \\\n",
       "0                  35                                      19   \n",
       "\n",
       "   Other syntax errors|Syntax  Multiple chemical issues|Chemical  \n",
       "0                           7                                  5  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outdict = defaultdict(list)\n",
    "for file in files:\n",
    "    df = pd.read_csv(os.path.join(psftdir, file)).drop(columns=['Unnamed: 0'], errors='ignore')\n",
    "    fname = file.replace('.csv', '')\n",
    "    info = fname\n",
    "\n",
    "    errdict_local = {}\n",
    "    for key, value in chemdict.items():\n",
    "        errdict_local[value] = {'Label': key, 'Occur': 0, 'Class': 'Chemical'}\n",
    "    for key, value in syndict.items():\n",
    "        errdict_local[value] = {'Label': key, 'Occur': 0, 'Class': 'Syntax'}\n",
    "    errdict_local['multiple'] = {'Label': 'Multiple chemical issues', 'Occur': 0, 'Class': 'Chemical'}\n",
    "\n",
    "    for idx, par, message in zip(df['ID'], df['Parsable'], df['Parse_warns']):\n",
    "        if par:\n",
    "            continue\n",
    "        if isinstance(message, float):\n",
    "            continue\n",
    "        check = sum(1 for ck in chemphs if ck in message)\n",
    "        all_check = sum(1 for ck in allphs if ck in message)\n",
    "        if check <= 1:\n",
    "            for tk in allphs:\n",
    "                if tk in message:\n",
    "                    errdict_local[tk]['Occur'] += 1\n",
    "                    break\n",
    "        else:\n",
    "            errdict_local['multiple']['Occur'] += 1\n",
    "        if all_check < 1:\n",
    "            raise ValueError(fname, idx, 'missing errors!', message)\n",
    "\n",
    "    outdict['Info'].append(info)\n",
    "    for k in errdict_local:\n",
    "        outdict['|'.join([errdict_local[k]['Label'], errdict_local[k]['Class']])].append(errdict_local[k]['Occur'])\n",
    "\n",
    "outdf = pd.DataFrame(outdict)\n",
    "outdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('data', exist_ok=True)\n",
    "outdf.to_csv('./data/errors.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Copyright ©2025  The Regents of the University of California (Regents). All Rights Reserved. Permission to use, copy, modify, and distribute this software and its documentation for educational, research, and not-for-profit purposes, without fee and without a signed licensing agreement, is hereby granted, provided that the above copyright notice, this paragraph and the following paragraphs appear in all copies, modifications, and distributions. Contact The Office of Technology Licensing, UC Berkeley, 2150 Shattuck Avenue, Suite 408, Berkeley, CA 94704-1362, otl@berkeley.edu.\n",
    "    \n",
    "    Created by John Smith and Mary Doe, Department of Statistics, University of California, Berkeley.\n",
    "\n",
    "    IN NO EVENT SHALL REGENTS BE LIABLE TO ANY PARTY FOR DIRECT, INDIRECT, SPECIAL, INCIDENTAL, OR CONSEQUENTIAL DAMAGES, INCLUDING LOST PROFITS, ARISING OUT OF THE USE OF THIS SOFTWARE AND ITS DOCUMENTATION, EVEN IF REGENTS HAS BEEN ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n",
    "\n",
    "    REGENTS SPECIFICALLY DISCLAIMS ANY WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE. THE SOFTWARE AND ACCOMPANYING DOCUMENTATION, IF ANY, PROVIDED HEREUNDER IS PROVIDED \"AS IS\". REGENTS HAS NO OBLIGATION TO PROVIDE MAINTENANCE, SUPPORT, UPDATES, ENHANCEMENTS, OR MODIFICATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
